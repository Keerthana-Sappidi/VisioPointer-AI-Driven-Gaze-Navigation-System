# VisioPointer-AI-Driven-Gaze-Navigation-System
VisioPointer is an assistive technology project that enables hands-free computer interaction using eye gaze tracking, blink detection, and voice commands.
It combines computer vision (MediaPipe), speech recognition (Vosk), and automation (PyAutoGUI) to create an accessible system for people with motor impairments or those who want a futuristic way of navigating their computer.

âœ¨ Key Features

ğŸ‘€ Eye Tracking â€“ Move the mouse cursor based on gaze direction.

ğŸ–±ï¸ Blink-to-Click â€“ Perform mouse clicks with intentional blinks.

ğŸ•’ Dwell Click â€“ Automatically click if the user looks at one spot for 2 seconds.

â¬†ï¸â¬‡ï¸ Smart Scrolling â€“ Scroll up or down by eye position.

ğŸ¤ Voice Commands â€“ Control the system with simple commands like:

"click" â†’ Mouse click

"scroll up" / "scroll down" â†’ Page navigation

"exit" â†’ Close the program

ğŸ§  Fuzzy Command Matching â€“ Handles mispronunciations with fuzzy matching.

ğŸ› ï¸ Tech Stack

OpenCV + MediaPipe â†’ Face mesh and eye landmark tracking

PyAutoGUI â†’ Mouse & keyboard automation

Vosk + PyAudio â†’ Offline speech recognition

Threading â†’ Parallel voice and gaze control

FuzzyWuzzy â†’ Robust voice command matching

ğŸ¯ Use Cases

Accessibility tool for users with motor disabilities

Hands-free navigation in sterile or restricted environments

Experimental project in HCI (Human-Computer Interaction)
